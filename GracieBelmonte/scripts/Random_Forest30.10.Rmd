---
title: "Random Forest"
output: html_document
date: "2025-10-15"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#load packages 


library(here)

library(dplyr)
 
library(tidyr) #for pivoting 

library(randomForest)


europe_data <- read.csv(here("GracieBelmonte","data","who_data.csv"))

europe_data <- europe_data %>%
  filter(who_region == "4_Eur") %>%
  select(-pm25_concentration) #we have excluded pm25 as it is too messy 

```

# 1. Introduction


The use of decision trees is both simple and
intuitive. They provide a straight forward, visual way to represent how
different variables influence a certain outcome by splitting data into
small groups based on predictor values. However, single decision trees
can be unstable and sensitive to training data. This problem is referred to as over-fitting, where a model performs well on known data but poorly on unseen data. And so minor changes in the
dataset can lead to major changes in the predicted outcomes. Hence this
makes them inefficient when generalising new, unseen data . 

Random Forest trees presents a way of overcoming these issues. The idea
is that they combine the predictions of many single decision trees into
one robust and accurate model. Instead of relying on a single tree, a
Random Forest builds multiple trees using different samples of the data
and random subsets of features at each split. The results from all trees
are then averaged (for regression) or voted on (for classification) to
generate the final prediction.

With this in mind, we can
confidently say that this model will be highly appropriate for our aim
of predicting PM10 concentrations in 2021 across European cities. Data
regarding air quality is complex. It can contain non-linear patterns,
interactions between pollutants and regional differences. A single
regression model may struggle to capture these elements, but Random
Forests can adapt to these complexities without requiring strong
assumptions about the data's structure.



 reference: [1] "<https://www.ibm.com/think/topics/random-forest>"

# 2. Data Preparation


Before training the Random Forest model, we needed to pre-process the
data to ensure it was suitable for prediction. In this section we have:

-   Identified the available years and isolate the range 2010- 2021.
    (everyone has probs done this so not just for my section)
-   Created a **training set** (2010- 2020) and a **test set** (2021).
-   Handled missing values appropriately, following the Statology (2023)
    approach.

```{r}
#check which years are avaible 
unique(europe_data$year)

# Quick summary of counts per year
table(europe_data$year)

colnames(europe_data)
```

So we could confirm the range and train on 2010-2021, 

```{r}
# filter relevent years and variables

# do i need to use minnies combined europe data instead?

europe_pm10 <- europe_data %>%
  filter(year >= 2010 & year <= 2021) %>%
  select(country_name, year, pm10_concentration, no2_concentration, population, latitude, longitude) 

#split training and test data

train_data <- europe_pm10 %>% filter( year < 2021)
test_data <- europe_pm10 %>% filter( year == 2021)

#replace missing values in predictors with column medians 
for (i in c("no2_concentration", "population")) {
  train_data[[i]][is.na(train_data[[i]])] <- median(train_data[[i]], na.rm = TRUE)
  test_data[[i]][is.na(test_data[[i]])] <- median(test_data[[i]], na.rm = TRUE)
}

#str(train_data)

```

### Summary of Prepartion Steps

-   The dataset was filtered to include only European countries and the
    years **2010-2021**, ensuring a consistent range for analysis.

The key variables retained were:

-   `pm10_concentration` - the target variable to be predicted.
-   `no2_concentration`, `population`, `longitude` and `latitude` -
    predictor variables.
-   `country_name` and `year` - identifying variable.

The dataset was divided into: - a **training set** (2010- 2020) used to
build the model, and - a **test set** (2021) used to evaluate its
predictive performance.

**Missing predictor values** were replaced using median imputation,
following the method described in:
 [2]"<https://www.statology.org/random-forest-in-r/>"



# 3. Train the Random Forest Model

This section implemented the Random Forest algorithm, again adapted
from: "<https://www.statology.org/random-forest-in-r/>"

```{r}
# random forest wont work with missing values in pm10?

train_data <- train_data %>% filter(!is.na(pm10_concentration))

#make this example reproducible - lock in the random number generators starting point 
set.seed(1)

#fit Random Forest model 
rf_model <- randomForest(
  formula = pm10_concentration ~ no2_concentration + population + latitude + longitude, 
  data = train_data
)

# view model summary 
rf_model 

```

### Summary of Model Implementation

-   The model was specified as:

**PM10 concentration** \~ **NOâ‚‚ concentration** + **population**

`pm10_concentration ~ no2_concentration + population`

-   The model was trained using **PM10 concentration** as the response
    variable, and **NO2 concentration** and **population** as predictor
    variables.
-   The Random Forest built **500 decision trees**, each trained on a
    random subset of the data and predictors.
-   Meaning the Random Forest algorithm combines the predictions of 500
    individual decision trees by averaging their outputs, a process
    known as **ensemble averaging**.
-   Thus this averaging process smooths out the variability from any one
    tree, reducing random noise and leading to a more accurate and
    stable model.

-The random seed 'set.seed(1)' ensures that results are reproducible and
so identical outcomes are produced each time the code is run.

-The model output shows: 

-   **Mean of Squared Residuals = 29.97915** - representing the average
    squared difference between predicted and actual PM10 values.
-   **% Variance Explained = 78.53%** - indicating that almost 80% of
    the variance in PM10 levels is explained by NO2 concentration,
    population, longitude and latitude.
    
    
-  Note that the **Mean of Squared Residuals** reflects the model's training error, how well it fits the data it was trained on. Later, in **Section 5**, we used the **Root Mean Squared Error (RSME)**. This measures the test error, which is the model's predictive accuracy on the unseen 2021 test data. 

# 4. Make predictions for 2021

-   In this section, the fitted Random Forest model is used to **predict
    PM10 concentrations** for the year **2021**.
-   The predictions are then added to the test data for later comparison
    with the **actual** (observed) PM10 values.
-   This procedure uses code
    from:[2]"<https://www.statology.org/random-forest-in-r/>",[3]"<https://bradleyboehmke.github.io/HOML/random-forest.html>"

```{r}
# make predictions on the 2021 test data 

# use the fitted Random Forest model to predict PM10 values for 2021 
predictions <- predict(rf_model, newdata = test_data)

# add the predicted PM10 values to the test dataset 
test_data$predicted_pm10 <- predictions

head(test_data)


```

### Summery of Prediction Process

-   The `predict()` function in R takes the fitted Random Forest model
    object (`rf_model`) and applies it new data (`test_data`).

-   `test_data\$predicted_pm10 \<- predictions` creates a new variable
    within 'test_data' data-frame that stores the model's predicted PM10
    values.

-   This step replicates the "out-of-box" prediction stage described in
    11.3:[3] "<https://bradleyboehmke.github.io/HOML/random-forest.html>",
    where model predictions are generated through a held-out test set.

-   The resulting dataset provides us with what we need for our next
    step of Model Evaluation, where the accuracy of these predictions
    will be measured and interpreted.



-   `pm10_concentration` is the actual observed PM10 value from the WHO
    dataset ( the "truth"), and `predicted_pm10` is the value the Random
    Forest model predicted using `no2_concentration`, `population`,
    `latitude` and `longitude` as inputs.

Looking at these results:

-   **Spain**: Actual PM10 = 23.23 and Predicted PM10 = 22.61; This
    shows the model's prediction is very close to the true value - high
    accuracy.

-   **Germany**: Actual PM10 = 14.53 and Predicted PM10 = 16.57; The
    model slightly overestimates, but still relatively close.
    

-  **Italy**: Actual PM10 = N/A and Predicted PM10 = 25.73; The model
produces a prediction even when the actual PM10 is missing - a key
strength of the model.


-  **France**: Actual PM10 = 12.15 and Predicted PM10 = 16.63; The model
over-predicts PM10 the most out the these 5 countries.

# 5. Evaluate Model Preformance with a metric

In order to assess the performance of my chosen model submission, the Random Forest model, our group has chosen to use the **Root Mean Squared Error (RSME)**.

We have implemented this using code adapted from:[4] "<https://stackoverflow.com/questions/60685866/how-do-i-find-out-the-rmse-of-a-random-forest-in-r>"

```{r}


RSME <- sqrt(mean((test_data$pm10_concentration - test_data$predicted_pm10)^2, na.rm = TRUE))

cat("Root Mean Squared Error (RMSE):", round(RSME, 3), "\n")

```

This value of **4.328** represents that, on average, the Random Forest model's prediction of PM10 differ from the actual, observed values by approximately 4.328 $\mu g/m^3$.

This suggests that when our model predicts PM10 levels for 2021 across Europe, there is a prediction error of around +/- 4 $\mu g/m^3$. Considering that our typical PM10 values are between 10 - 30 $\mu g/m^3$, the value of **4.328** shows the model performs **reasonably well**, meaning it captures overall patterns, but not perfectly. 


# 6. Visualise Predictions


```{r}
# load ggplot2 for graphs 

#scatter Plot 

library(ggplot2)

#scatter plot of predicted vs actual PM10 for 2021 
ggplot(test_data, aes( x = pm10_concentration, y = predicted_pm10)) +
  geom_point(colour = "steelblue", size = 3, alpha = 0.7) +
  geom_abline(slope= 1, intercept = 0, colour= "red", linetype = "dashed") +
  labs(
    title = "Predicted vs Actual PM10 concentrations (2021)",
    x = "Actual PM10 Concentration",
    y = "Predicted PM10 Concentration"
  ) + 
  theme_minimal(base_size = 13)

```

-   We plot **Actual (observed) PM10 concentrations in 2021** against
    **Predicted PM10 concentrations from the Random Forest**
-   The red dashed line is the "perfect prediction" line , if the model
    was 100% accurate , every point would lie exactly on this line.

What we can see:

\-**Strong positive relationship**:The points generally follow a clear
upward trend along the dashed red line. The model has done well at
capturing the overall pattern of how PM10 varies across locations.

\-**Slight under-prediction at higher PM10 levels**: For very high actual
values, many points fall below the red line, indicating that model tends
to underestimate extreme pollution levels.

# 7. Analyse Feature Importance

A useful strength of the Random Forest model is that they can provide a
direct measure of **feature Importance**, in other words, quantifying
how much each variable contributed to the models prediction.

This is calculated using how much each variable reduces the model's
prediction error across all trees in the forest. We used code adapted from
[5]"<https://stats.stackexchange.com/questions/153663/how-to-get-the-most-important-variables-in-random-forests-in-r>")

```{r}

# extract feature importance from the Random Forest Model 

importance_df <- importance(rf_model) %>%
  data.frame() %>%
  mutate(Feature = rownames(.))


#Display
colnames(importance_df)

#Plot Feature Importance 
library(ggplot2)

ggplot(importance_df,aes(x = reorder(Feature, IncNodePurity), y = IncNodePurity)) +
  geom_bar(stat = "identity", fill = "steelblue", alpha = 0.8) +
  coord_flip()+
  labs(
    title = "Feature Importance in Random Forest Mode", 
    x = "Predictor Variable",
    y = "Importance (Increase in MSE)"
  ) +
  theme_minimal(base_size = 13)




```

## Discussion of the graph

-   The x-axis represents the importance score `IncNodePurity`, which is
    the amount each variable improves the model's ability to make
    accurate splits across all trees in the Random Forest.
-   The y-axis lists the predictors: `longitude`, `latitude`,
    `no2_concentration` and `population`.

### Interpretation

-   `Longitude` was the most influential variable, the model relies
    heavily on a location's east-west position to predict PM10,
    suggesting that there is **strong spatial patterns** in air
    pollution across Europe.
-   `Latitude` is the second most important variable, again suggesting
    that geography plays a major role in determining PM10. This could be
    due to climate or population distribution patterns.
-   `no2_concentration` ranks third, indicating that there is clear
    environmental relationship, higher no2 levels would align with
    higher PM10 values
-   `population` has the lowest importance score, but it would still
    contribute to prediction. More densely populations would have higher
    pollutions levels, however the other predictors would be more
    explanatory than population.

# 8. Conclusion

In conclusion, by combining multiple decision trees to capture non-linear patterns between air pollution, geography and population, the Random Forest model provided an effective approach to predicting PM10 levels across Europe. 

The **Mean of Squared Residuals** and **RSME** of **29.98** and **4.33**, respectively, indicates a reasonable generalisation to unseen 2021 data. Hence we can confidently say it is a robust baseline for comparison with the other group methods. 

A key benefit of the Random Forest, that is lacking in other model submissions, is it's ability to handle missing data and still produce interpretable results. This makes it a realistic tool for ensemble modelling, since incomplete data is common and often unavoidable in real-world situations. 

Thus, although it may not be the most accurate choice of model for predicting PM10 values across Europe, it remains one of the most **practical** approaches for handling complex, environmental data. 


# 9. References 


References for assessment 1 

 

[1] https://www.ibm.com/think/topics/random-forest 

(Introducing random forest) 

[2] https://www.statology.org/random-forest-in-r/ 

(missing data + algorithm â€“ step 2, making predictions â€“ step 4) 

[3] https://bradleyboehmke.github.io/HOML/random-forest.htm 

(making predictions â€“ 11.3) 

[4] https://stackoverflow.com/questions/60685866/how-do-i-find-out-the-rmse-of-a-random-forest-in-r 

(evaluate performance with RSME) 

[5] https://stats.stackexchange.com/questions/153663/how-to-get-the-most-important-variables-in-random-forests-in-r 

(Analysing feature importance)  
