---
title: "Minnie_lin_reg"
author: "Minnie"
date: "2025-10-18"
output: html_document
---

```{r loading}
library(dplyr)
data=read.csv("who_data.csv")
who_data=subset(data,select=-c(X,X.1,X.2,X.3,who_ms))
#convert numeric-like columns stored as character to numeric
num_cols= c("pm10_concentration","pm25_concentration","no2_concentration",
              "pm10_tempcov","pm25_tempcov","no2_tempcov","population")
who_data[num_cols] =lapply(who_data[num_cols], as.numeric) # set the data as numeric

who_data$type_of_stations =as.character(who_data$type_of_stations)
who_data$who_region =as.factor(who_data$who_region)

#and finally, we can see Turkey isn't defined properly in the dataset, so we add 
who_data$country_name[who_data$iso3 == "TUR"] <- "Turkey"


europe_data= who_data %>%
  filter(who_region=="4_Eur")%>%
  select(-pm25_concentration)
clean_data_europe= na.omit(europe_data)
```

# Requirements
```{r}
if(!require("ggplot2")) install.packages("ggplot2")
if(!require("caret")) install.packages("caret")
```

# Section 1: Linear regression models

The first model we explored for prediction was the commonly seen linear regression. From previous EDA that we carried out in Assessment 0, we found that after using the openair package for time series of pm10 concentration for different cities in Europe, there appeared to be a somewhat linear trend- suggesting regression should be an appropriate model.

Linear regression cannot work if we have missing values, so for this we use our clean_europe_data. Our goal is to predict the pm10 concentration for 2021 (2022 contains insufficient data for testing) using data from different cities in Europe.

## Literary review

 Explicitly state the prediction goal: e.g., “forecasting PM₁₀ levels for 2021 across European cities from NO₂ and population metrics.”
Quantify and justify your performance metric:
Why RMSE? Would MAE or adjusted R² better capture real-world generalisability?
Compare to a naïve baseline (e.g., “PM₁₀₍₂₀₂₁₎ ≈ PM₁₀₍₂₀₂₀₎”) to show improvement is meaningful.
Discuss train/test philosophy: why you left out 2021, and how this mimics “future data” prediction.
Mention how your approach could generalise beyond Europe.



## Model equation
We decided to include the following covariates in our model:

- **year** (to capture time effects) - numeric, discrete, 2013-2021 once cleaned

- **no2_concentration** we found this was strongly correlated with pm10_concentration so may contribute to prediction.

-  **country_name** - categorical (we focused on european countries).

- **latitude/longitude** - could be interesting exploration of location.
We remove the coverage variables, as these don't directly contribute to prediction.

- **population/log-population**- We include the **population** variable, (an indicator of city size), numeric, continuous, but due to its large range, we found using a log transform of this improved our results, so this is also included in our model. 

-**country_name**- we include this as a ...variable .. as we can use this to 


So applying this we refine our dataset further: 
```{r further removal}
clean_data_europe_rem= clean_data_europe %>%
select(-iso3, -pm10_tempcov, -pm25_tempcov,-who_region,-no2_tempcov, -type_of_stations)%>%
  filter(year != 2022)%>% #EDA showed insufficient data for testing for 2022
  mutate(log_population = log(population)) %>% # EDA showed a transform was a better predictor of results
  na.omit(europe_data) #lin regression can't have missing data
```

We explored linear regression models for pm10 concentration in our EDA from Assessment 0, and found that we could improve our model by exploring non-linear relationships. At first we explored models such as this : 

$$
\text{PM}_{10,i} = \beta_0 + \beta_1 \cdot \text{Year}_i+\beta_2 \cdot \text{log_population}_i + \beta_3 \cdot \text{longitude}_i + \beta_4 \cdot \text{latitude}_i+ \text{no2_concentration}+ \varepsilon_i,
$$
where $\varepsilon_i \sim N(0,\sigma^2)$.

But we will focus on the following model: 
$$
\text{PM}_{10,i} = \beta_0 + \beta_1 \cdot \text{Year}_i+\beta_2 \cdot \text{Year}_i^2+\beta_3 \cdot \text{population}+\beta_4 \cdot \text{log_population} +\beta_5\text{no2_concentration}+ \beta_6\text{no2_concentration}^2+\beta_7\text{no2_concentration}^3+\beta_8 \cdot \text{longitude}* \text{latitude}_i+ + \varepsilon_i,
$$
Our choices were made by combining EDA with: 
- Year appears to 
- no_2 concentration doesn't appear to have a particularly linear relationship, so by ... 
- log_population transform fits our data better since population has large ranges 
- longitude and latitude are strongly correlated so we ... 


Next split our model into 2 subsets, the training dataset that includes all data from our cleaned Europe data set but without our values for 2021 (since this is what our model tries to predict), and the test set which we use for out of sample analysis later. 

```{r model}
library(caret) #We use the package 'caret' that we saw in the workshop 2.3. 
set.seed(2)
train_data=subset(clean_data_europe_rem, year != 2021)
test_data_2021=subset(clean_data_europe_rem, year == 2021)

#using our formula aforementioned:
lm_formula_pm10=pm10_concentration ~ poly(year, 2)+no2_concentration+poly(no2_concentration,3) +population+log_population+ latitude*longitude
```

Now we use cross validation to train our linear regression model
```{r cv}
#now using cv: (we use 10 folds)
modelcv=train(lm_formula_pm10, data = train_data, method = "lm" ,trControl=trainControl(method = "cv",number=10),preProcess = c("center","scale"))

summary(modelcv$finalModel)
modelcv$results
```


The estimated coefficients can be interpreted as follows:

-   **Intercept**: $\hat{\beta}_0 = 908.668419$\
    This represents the expected ${PM}_{10}$ concentration when
    all other variables are zero.
    Since this situation is not realistic, the intercept is not of
    direct interest.\
    
  -**Year**: $\hat{\beta}_1 = -0.435221$ \
    Holding other variables constant, by increasing the year by 1, we expect a decrease of 0.435221 per unit of pm_10 concentration. As we saw from our EDA, pm10 concentration appeared to have a negative correlation with year. This variable is very statistically significant.\

-   **No2_concentration**: $\hat{\beta}_2 =0.231806$. For every increase by 1 unit of No2, pm10 is expected to increase by 0.231806 units, assuming the other factors remain unchanged. We see that this has a very small p-value, suggesting it is statistically significant.\

-   **log_population**: $\hat{\beta}_3 =0.237393$ \
    Holding other variables constant, additional increase in the transformed population by 1 unit is associated with an increase of about $0.237393$ units in ${PM}_{10}$.This suggests a slight positive trend in pollution and pm10 concentration which would make sense given a higher population ... 
    Though it has the largest p-value of our variables, the effect is highly statistically significant, showing that log_population size is related to pm10 pollution levels. \

  -**Latitude**: $\hat{\beta}_4=-0.414233$
  
  -**Longitude**: $\hat{\beta}_5 =0.326300$.  \
    
The model suggests that PM₁₀ concentrations are mainly explained by NO₂ levels, geographic location, and time.
NO₂ has a strong positive relationship with PM₁₀, indicating shared pollution sources.
Over the years (2013–2020), PM₁₀ concentrations have generally decreased, especially in northern and western European cities.
Population size shows a mild positive effect, possibly reflecting urban density, though it’s less statistically robust.

## Model fit

```{r compare}
R2_train= R2(pred = predict(modelcv, train_data),
               obs = train_data$pm10_concentration)
cat("Model cv performance:", round(R2_train, 3), "\n")
```

The cross-validated linear regression achieved an R^2 of 0.491 on the training set. This means that the model explains 49.1% of the data. 


## Model assumptions

We test our model's fit on the linear regression assumptions:
```{r pred}
par(mfrow = c(2, 2))
plot(modelcv$finalModel)
```
As we can see from the :

*Residuals vs fitted :* The residuals are fairly randomly scattered, but with a curved, quadratic distribution suggesting our assumption for linearity doesn't entirely hold. 

*Q-Q residuals:* The residuals mostly lie in a diagonal line apart from at the tails, but overall we can see the assumptoin of normality holds.  apart from at the tailes where 

*Scale-location:* The residuals are randomly scattered around the line, so we can assume that the constant variance assumption is satisfied. 

*Residuals vs leverage:* We see most of our data is clustered around the left hand side of the graph, suggesting we have a left skew. There appear to be no extreme outliers. 


Now using our model we can use our true pm10 data for 2021 and test: 
```{r predictions}


test_data_2021$predicted_pm10 <- predict(modelcv, newdata = test_data_2021)
results_2021 <- data.frame(
  city = test_data_2021$city,
  country = test_data_2021$country_name,
  actual_pm10 = test_data_2021$pm10_concentration,
  predicted_pm10 = test_data_2021$predicted_pm10
)

```

This means that ...

## Model visualisation
We visualise our results as follows: 
```{r visual}
library(ggplot2)
ggplot(results_2021, aes(
  x = actual_pm10,y = predicted_pm10,color = country)) +
  geom_point(alpha = 0.8, size = 2) +
  geom_abline(intercept = 0, slope = 1, color = "black", linetype = "dashed") +geom_smooth(method = "lm", se = FALSE, color = "darkred", linetype = "dotted")+
  labs(title = "Actual vs Predicted PM10 concentrations for cities in Europe (for 2021)",
    x = "Actual PM10 concentration",
    y = "Predicted PM10 concentration",
    color = "Country"
  ) +
  theme_minimal(base_size = 10) +
  theme(legend.position = "right",
    plot.title = element_text(face = "bold"))

```
Clearly we can see most of our data is clustered around the lower left of our data set, with the excpetion of a few outliers such as France, Israel, Ireland and Italy, removing these would increase the model performance, however this would also introduce a bias to our model.


## Extending our linear regression by regularising
To improve our model, we build upon the ideas of linear regression by regularising. 
There are a variety of ways of doing this, we focus on the following methods: - Ridge 

-Lasso

-Elastic (combines Ridge and Lasso)

### Ridge
```{r ridge}
set.seed(2)
#first we try ridge regression
ridge_model <- train(lm_formula_pm10,data = train_data,method = "glmnet",
  trControl = trainControl(method = "cv", number = 5),preProcess = c("center","scale"),
  tuneGrid = expand.grid(alpha = 0,lambda = seq(0.0001, 1, length = 50))
)
ridge_model$bestTune
plot(ridge_model)

#so now predicting for 2021:
test_data_2021$predicted_pm10_ridge <- predict(ridge_model, newdata = test_data_2021)
```
This illustration demonstrates ... 

### LASSO
```{r Lasso}
set.seed(2)

lasso_model <- train(lm_formula_pm10,data = train_data,
  method = "glmnet",trControl = trainControl(method = "cv", number = 5),preProcess = c("center","scale"),
  tuneGrid = expand.grid(alpha = 1,lambda = seq(0.0001, 1, length = 50))
)
lasso_model$bestTune
plot(lasso_model)
test_data_2021$predicted_pm10_lasso <- predict(lasso_model, newdata = test_data_2021)

```
Similar to Ridge, we can see that the RMSE increases as the regularisation paramter increases, with our best results being around ... 


### Elastic 
```{r elastic}
set.seed(2)

elastic_model <- train(lm_formula_pm10,data = train_data,
method = "glmnet",trControl = trainControl(method = "cv", number = 5),preProcess = c("center","scale"),
  tuneGrid = expand.grid(alpha = seq(0, 1, length = 10),lambda = seq(0.0001, 1, length = 50)))

elastic_model$bestTune
plot(elastic_model)

test_data_2021$predicted_pm10_elastic <- predict(elastic_model, newdata = test_data_2021)

```

### Comparison

```{r comparison}
comparison <- rbind(
  Linear = postResample(results_2021$predicted_pm10, results_2021$actual_pm10),
  Ridge = postResample(test_data_2021$predicted_pm10_ridge, test_data_2021$pm10_concentration),
  LASSO = postResample(test_data_2021$predicted_pm10_lasso, test_data_2021$pm10_concentration),
  Elastic=postResample(test_data_2021$predicted_pm10_elastic, test_data_2021$pm10_concentration)
)
comparison

```

## Conclusions
To conclude our section on linear regression, we found our initial linear regression model wasn't too accurate, only accounting for 41% of our data. To resolve this we regularised our linear regression model by using lasso and ridge methods. 
We also used transforms of variables, such as log population and cubic terms for the no2 concentration. 

Significant predictors we found were year (which is to be expected given the negative correlation of our pm10 concentrations over time), ... , ... 

To amend this and further our analysis, we would need to consider additional explanatory variables, these could include: 

1. Weather conditions - temperature, wind speed, humidity. 
2. Industrial emissions. 
3. Traffic density. 


