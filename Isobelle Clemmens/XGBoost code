
import xgboost as xgb
import pandas as pd
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedKFold
from sklearn.model_selection import GridSearchCV, train_test_split
from numpy import absolute


with open('who_data.csv', encoding='utf-8', errors='ignore') as f:
   df = pd.read_csv(f)

   eu_df = df[df['who_region'] == '4_Eur']
   eu_df = eu_df[['year', 'pm10_concentration', 'pm25_concentration', 'no2_concentration','population', 'latitude', 'longitude']]

   eu_df = eu_df.dropna(subset = ['pm10_concentration'])


# Split into model input and prediction target
X = eu_df.drop(columns = 'pm10_concentration')
y = eu_df['pm10_concentration']
# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define parameter grid
param_grid = {
    'max_depth': [3, 5, 7],
    'min_child_weight': [1, 3, 5],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0],
    'learning_rate': [0.01, 0.1, 0.3]
}

# Use GridSearchCV to optimise hyperparameters
model = xgb.XGBRegressor(random_state=42)
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)
grid_search.fit(X_train, y_train)

# Print best parameters
print(f"Best parameters: {grid_search.best_params_}")
print(f"Best score: {grid_search.best_score_}")

newmodel = xgb.XGBRegressor(**grid_search.best_params_, random_state=42)


cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=42)
# evaluate model
scores = cross_val_score(model, X, y, scoring='neg_root_mean_squared_error', cv=cv, n_jobs=-1)
newscores = cross_val_score(newmodel, X, y, scoring = 'neg_root_mean_squared_error', cv = cv, n_jobs = -1)


# force scores to be positive
scores = absolute(scores)
print('Mean MAE before grid search: %.3f (%.3f)' % (scores.mean(), scores.std()) )

newscores = absolute(newscores)
print('Mean MAE after grid search: %.3f (%.3f)' % (newscores.mean(), newscores.std()) )

# Visualise results

train = xgb.train(grid_search.best_params_, xgb.DMatrix(X_train, label=y_train))
predictions = train.predict(xgb.DMatrix(X_test))

import matplotlib.pyplot as plt
plt.scatter(y_test, predictions, linewidths=0.5, marker = 'o')
plt.plot(range(0,130), range(0,130), color = 'red')
plt.xlabel('True pm10 concentration')
plt.ylabel('Predicted pm10 concentration')
plt.title('XGBoost Predicted vs True PM10 Concentration')
plt.show(block = False)