@article{CHEN2019104934,
title = {A comparison of linear regression, regularization, and machine learning algorithms to develop Europe-wide spatial models of fine particles and nitrogen dioxide},
journal = {Environment International},
volume = {130},
pages = {104934},
year = {2019},
issn = {0160-4120},
doi = {https://doi.org/10.1016/j.envint.2019.104934},
url = {https://www.sciencedirect.com/science/article/pii/S0160412019304404},
author = {Jie Chen and Kees {de Hoogh} and John Gulliver and Barbara Hoffmann and Ole Hertel and Matthias Ketzel and Mariska Bauwelinck and Aaron {van Donkelaar} and Ulla A. Hvidtfeldt and Klea Katsouyanni and Nicole A.H. Janssen and Randall V. Martin and Evangelia Samoli and Per E. Schwartz and Massimo Stafoggia and Tom Bellander and Maciek Strak and Kathrin Wolf and Danielle Vienneau and Roel Vermeulen and Bert Brunekreef and Gerard Hoek},
keywords = {Land use regression, Fine particles, Nitrogen dioxide, Machine learning},
abstract = {Empirical spatial air pollution models have been applied extensively to assess exposure in epidemiological studies with increasingly sophisticated and complex statistical algorithms beyond ordinary linear regression. However, different algorithms have rarely been compared in terms of their predictive ability. This study compared 16 algorithms to predict annual average fine particle (PM2.5) and nitrogen dioxide (NO2) concentrations across Europe. The evaluated algorithms included linear stepwise regression, regularization techniques and machine learning methods. Air pollution models were developed based on the 2010 routine monitoring data from the AIRBASE dataset maintained by the European Environmental Agency (543 sites for PM2.5 and 2399 sites for NO2), using satellite observations, dispersion model estimates and land use variables as predictors. We compared the models by performing five-fold cross-validation (CV) and by external validation (EV) using annual average concentrations measured at 416 (PM2.5) and 1396 sites (NO2) from the ESCAPE study. We further assessed the correlations between predictions by each pair of algorithms at the ESCAPE sites. For PM2.5, the models performed similarly across algorithms with a mean CV R2 of 0.59 and a mean EV R2 of 0.53. Generalized boosted machine, random forest and bagging performed best (CV R2~0.63; EV R2 0.58–0.61), while backward stepwise linear regression, support vector regression and artificial neural network performed less well (CV R2 0.48–0.57; EV R2 0.39–0.46). Most of the PM2.5 model predictions at ESCAPE sites were highly correlated (R2 > 0.85, with the exception of predictions from the artificial neural network). For NO2, the models performed even more similarly across different algorithms, with CV R2s ranging from 0.57 to 0.62, and EV R2s ranging from 0.49 to 0.51. The predicted concentrations from all algorithms at ESCAPE sites were highly correlated (R2 > 0.9). For both pollutants, biases were low for all models except the artificial neural network. Dispersion model estimates and satellite observations were two of the most important predictors for PM2.5 models whilst dispersion model estimates and traffic variables were most important for NO2 models in all algorithms that allow assessment of the importance of variables. Different statistical algorithms performed similarly when modelling spatial variation in annual average air pollution concentrations using a large number of training sites.}
}

@article{performancemetric,
author = {Plevris, Vagelis and Solorzano, German and Bakas, Nikolaos and Ben Seghier, Mohamed},
year = {2022},
month = {06},
pages = {},
title = {Investigation of performance metrics in regression analysis and machine learning-based prediction models},
doi = {10.23967/eccomas.2022.155}
}


@online{ibm,
author= {Eda Kavlakoglu},
publisher={IBM}
title= {What is Random Forest?},
url= {https://www.ibm.com/think/topics/random-forest}
}

@online{statology,
author={ZACH BOBBITT},
publisher={Statology},
year={2013},
title={How to Build Random Forests in R},
url={https://www.statology.org/random-forest-in-r/}
}

@online{bradley,
author={Bradley Boehmke},
title={Hands on machine learning with R, Random Forests},
url={https://bradleyboehmke.github.io/HOML/random-forest.html}
}
